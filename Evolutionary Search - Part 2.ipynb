{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evolutionary Algorithms (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In this chapter we take a closer look at some of the search operators and algorithmic choices that we took for granted so far. In particular, we reconsider selection, crossover, mutation, and the topology of the population itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.utils import io\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We will start by considering the one max problem again, where a solution is a vector of length _n_, consisting of binary numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To keep code examples simple, we will not use our wrapper class but lists again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_solution():\n",
    "    individual = [random.choice([0,1]) for _ in range(n)]\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The fitness function as well as variation operators are still the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_fitness(solution):\n",
    "    return sum(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We start with the operators that we have used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def mutate(individual):\n",
    "    P_mutate = 1/len(individual)\n",
    "    copy = individual[:]\n",
    "    for position in range(len(individual)):\n",
    "        if random.random() < P_mutate:\n",
    "            copy[position] = 1 - copy[position]\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def singlepoint_crossover(parent1, parent2):\n",
    "    pos = random.randint(0, len(parent1))\n",
    "    offspring1 = parent1[:pos] + parent2[pos:]\n",
    "    offspring2 = parent2[:pos] + parent1[pos:]\n",
    "    return offspring1, offspring2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The first selection operator we considered was tournament selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tournament_size = 3\n",
    "def tournament_selection(population, replacement=False):\n",
    "    if replacement:\n",
    "        candidates = random.choices(population, k = tournament_size)\n",
    "    else:\n",
    "        candidates = random.sample(population, tournament_size)\n",
    "        \n",
    "    winner = max(candidates, key = lambda x: get_fitness(x))\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A general problem in evolutionary search is finding the right balance between exploration and exploitation. Using the wrong operators may lead to premature convergence, or the search may never converge at all at an optimum. As a first step towards understanding what is happening inside the population of a genetic algorithm, we will consider the _average fitness_ of the population as well as the _diversity_ within the population in addition to the best fitness value we already tracked in the past. For this, we first define the difference between two individuals as the hamming distance between the vector representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def hamming_distance(individual1, individual2):\n",
    "    return sum(c1 != c2 for c1, c2 in zip(individual1, individual2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can now calculate an overall population diversity as the sum of pairwise hamming distances for all pairs of individuals in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def pairwise_distance(population):\n",
    "    distances = 0\n",
    "    for i in range(len(population)-1):\n",
    "        for j in range(i, len(population)):\n",
    "           distances += hamming_distance(population[i], population[j]) \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We need to set the parameters of our genetic algorithm first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "population_size = 20\n",
    "P_xover   = 0.7\n",
    "max_steps = 1000\n",
    "selection = tournament_selection\n",
    "crossover = singlepoint_crossover\n",
    "\n",
    "# These lists track values throughout the evolution\n",
    "# so we can compare the behaviour of different operators\n",
    "fitness_values = []\n",
    "diversity_values = []\n",
    "mean_fitness_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In the lecture we discussed that there are many different variations of all the search operators involved in a genetic algorithm. We will now look at a couple of relevant search operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Survivor Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Most evolutionary algorithms use a fixed population size, so we need a way of going from (parents + offspring) to the next generation. \n",
    "- In age-based selection one usually produces as many offspring as there are parents, and then replaces the parents with the offspring. \n",
    "- In fitness-based selection, we rank the parents and the offspring, and take the best of all.\n",
    "\n",
    "We saw both versions last time in the context of evolution strategies, but can also create versions of a genetic algorithm. In a generational genetic algorithm the offspring replaces the parents, while in a steady state genetic algorithm we apply fitness-based survivor selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Elitism is a special case, where the best individuals of the population always survive, while other means are used for the rest of the population. We implement a simple version of elitism by simply ranking the population by diversity and taking the top `elite_size` elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "elite_size = int(population_size * 0.05)\n",
    "\n",
    "def elitism(population):\n",
    "    population.sort(key=lambda k: get_fitness(k), reverse=True)\n",
    "    return population[:elite_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's revisit the standard genetic algorithm with a generational selection model, integrated with elitism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def ga():\n",
    "    population = [get_random_solution() for _ in range(population_size)]\n",
    "    fitness_values.clear()\n",
    "\n",
    "    # This could probably be written in a single line, but let's keep it explicit\n",
    "    best_fitness = -1\n",
    "    for p in population:\n",
    "        fitness = get_fitness(p)\n",
    "        if fitness > best_fitness:\n",
    "            best_fitness = fitness\n",
    "        fitness_values.append(best_fitness)\n",
    "\n",
    "    diversity_values.append(pairwise_distance(population))\n",
    "    mean_fitness_values.append(mean([get_fitness(x) for x in population]))\n",
    "\n",
    "    while len(fitness_values) < max_steps:\n",
    "\n",
    "        new_population = elitism(population)\n",
    "        while len(new_population) < len(population):\n",
    "            parent1 = selection(population)\n",
    "            parent2 = selection(population)\n",
    "\n",
    "            if random.random() < P_xover:\n",
    "                offspring1, offspring2 = crossover(parent1, parent2)\n",
    "            else:\n",
    "                offspring1, offspring2 = parent1[:], parent2[:]\n",
    "\n",
    "            offspring1 = mutate(offspring1)\n",
    "            offspring2 = mutate(offspring2)\n",
    "            \n",
    "            fitness1, fitness2 = get_fitness(offspring1), get_fitness(offspring2)\n",
    "\n",
    "            if fitness1 > best_fitness:\n",
    "                best_fitness = fitness1\n",
    "            fitness_values.append(best_fitness)\n",
    "            if fitness2 > best_fitness:\n",
    "                best_fitness = fitness2\n",
    "            fitness_values.append(best_fitness)\n",
    "            \n",
    "            new_population += [offspring1, offspring2]\n",
    "\n",
    "        population = new_population\n",
    "        diversity_values.append(pairwise_distance(population))\n",
    "        mean_fitness_values.append(mean([get_fitness(x) for x in population]))\n",
    "\n",
    "    return max(population, key=lambda k: get_fitness(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The alternative was the steady state genetic algorithm, where we select two parents, derive their offspring, and then do fitness-based survivor selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def steadystatega():\n",
    "    population = [get_random_solution() for _ in range(population_size)]\n",
    "    best_fitness = -1\n",
    "    fitness_values.clear()\n",
    "    \n",
    "    for p in population:\n",
    "        fitness = get_fitness(p)\n",
    "        if fitness > best_fitness:\n",
    "            best_fitness = fitness\n",
    "            best_solution = p\n",
    "        fitness_values.append(best_fitness)\n",
    "    diversity_values.append(pairwise_distance(population))\n",
    "    mean_fitness_values.append(mean([get_fitness(x) for x in population]))\n",
    "    \n",
    "    while len(fitness_values) < max_steps:                \n",
    "        parent1 = selection(population)\n",
    "        parent2 = selection(population)\n",
    "        \n",
    "        p1 = population.index(parent1)\n",
    "        p2 = population.index(parent2)\n",
    "\n",
    "        if random.random() < P_xover:\n",
    "            offspring1, offspring2 = crossover(parent1, parent2)\n",
    "        else:\n",
    "            offspring1, offspring2 = parent1[:], parent2[:]\n",
    "\n",
    "        offspring1 = mutate(offspring1)\n",
    "        offspring2 = mutate(offspring2)\n",
    "        \n",
    "        best1, best2 = sorted([parent1, parent2, offspring1, offspring2], key=lambda x: get_fitness(x), reverse=True)[:2]\n",
    "        population[p1] = best1\n",
    "        population[p2] = best2\n",
    "\n",
    "        fitness1, fitness2 = get_fitness(best1), get_fitness(best2)\n",
    "\n",
    "        if fitness1 > best_fitness:\n",
    "            best_fitness = fitness1\n",
    "        fitness_values.append(best_fitness)\n",
    "        if fitness2 > best_fitness:\n",
    "            best_fitness = fitness2\n",
    "        fitness_values.append(best_fitness)\n",
    "        \n",
    "        # To make plots comparable with the generational GA\n",
    "        if len(fitness_values) % population_size == 0:\n",
    "            diversity_values.append(pairwise_distance(population))\n",
    "            mean_fitness_values.append(mean([get_fitness(x) for x in population]))\n",
    "            \n",
    "    return best_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note that there are further possibilities for variation here: Instead of replacing the selected parents in the population, we could select other individuals (e.g., the worst individuals)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To consider the effects on diversity, let's compare diversity and fitness throughout one run each. We'll increase `n` to make the problem slightly more challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 4))\n",
    "n = 100\n",
    "max_steps = 1000\n",
    "population_size = 20\n",
    "\n",
    "with io.capture_output() as captured: \n",
    "    elite_size = 0\n",
    "    fitness_values = []\n",
    "    diversity_values = []\n",
    "    mean_fitness_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"No elitism\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"No elitism\")\n",
    "    axes[2].plot(fitness_values, label=f\"No elitism\")\n",
    "\n",
    "    elite_size = 1\n",
    "    fitness_values = []\n",
    "    diversity_values = []\n",
    "    mean_fitness_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"E1\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"E1\")\n",
    "    axes[2].plot(fitness_values, label=f\"E1\")\n",
    "    \n",
    "    elite_size = 10\n",
    "    fitness_values = []\n",
    "    diversity_values = []\n",
    "    mean_fitness_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"E10\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"E10\")\n",
    "    axes[2].plot(fitness_values, label=f\"E10\")\n",
    "    \n",
    "    fitness_values = []\n",
    "    diversity_values = []\n",
    "    mean_fitness_values = []\n",
    "    steadystatega()\n",
    "    axes[0].plot(diversity_values, label=f\"SS-GA\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"SS-GA\")\n",
    "    axes[2].plot(fitness_values, label=f\"SS-GA\")\n",
    "\n",
    "axes[0].set_title('Population Diversity')\n",
    "axes[0].legend()\n",
    "axes[1].set_title('Mean Population Fitness')\n",
    "axes[1].legend()\n",
    "axes[2].set_title('Fitness Evolution')\n",
    "axes[2].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "As usual results may vary between runs, since these are randomised algorithms. However, a general trend we should see in the above plots is that the population diversity of the steady state GA reduces much slower than in a generational GA, and also the average fitness value in the population remains lower. The large elitism size of `10` means that the algorithm can run more generations with the same number of fitness evaluations, which is why it continues longer than the others in the first two plots. A small elitism size tends to generally lead to a better average fitness in this configuration. The best performing version will differ between runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parent Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A major difference between the evolution strategies we considered initially and the canonical genetic algorithm we looked at afterwards is the parent selection strategy. In classical evolution strategies all Î¼ (mu) parents are involved in recombination, and the survivor selection is what drives the selective pressure. In genetic algorithms, instead, the parent selection applies selective pressure. \n",
    "\n",
    "We started off with tournament selection because it is the quickest to implement. A traditionally more common variant is fitness proportionate selection, where the probability of an individual to be selected is proportional to its fitness value. The selection thus first calculates the total fitness sum, and then probabilistically chooses an individual by sampling a number in the range between 0 and the total fitness sum. An important requirement is that the population is sorted by fitness values, starting with the best individual (largest fitness).  This selection operator is also known as _roulette wheel selection_.\n",
    "\n",
    "In our simple implementation, we create a list of tuples `fitness_list` that stores individuals with their fitness. Obviously, there's some redundant fitness calculations here; in practice one would cache fitness values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def roulette_selection(population):\n",
    "    fitness_sum = sum([get_fitness(x) for x in population])\n",
    "    population.sort(key=lambda x: get_fitness(x), reverse=True)\n",
    "    pick = random.uniform(0, fitness_sum)\n",
    "    current = 0\n",
    "    for x in population:\n",
    "        current += get_fitness(x)\n",
    "        if current > pick:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To evaluate this, let's create a simple example population for `n=5` with individuals with fitness 5, 4, 3, 2, 1, and 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "example_population = [ [1,1,1,1,1], [0,1,1,1,1], [0,0,1,1,1], [0,0,0,1,1], [0,0,0,0,1], [0,0,0,0,0]  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Applying this selection operator will more likely select the best individual(s) (but may select worse individuals as well). We can do a simple experiment by sampling repeatedly from our `example_population` and looking at the resulting histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "counts = {x: 0 for x in range(len(example_population))}\n",
    "\n",
    "for i in range(1000):\n",
    "    selected = roulette_selection(example_population)\n",
    "    index = example_population.index(selected)\n",
    "    counts[index] = counts[index] + 1\n",
    "    \n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.xticks(list(counts.keys()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A problem with fitness proportionate selection is that individuals that have a much better fitness value will dominate the selection. For example, let's skew our example population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "example_population = [ [1,1,1,1,1], [0,1,0,0,0], [1,0,0,0,0], [0,0,1,0,0], [0,0,0,1,0],[0,0,0,0,0] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In this population, the first individual has fitness value 5, while the other individuals have fitness 1 and 0. The sum of fitness values is 9, and so the first individual has a probability of 56% of being selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "counts = {x: 0 for x in range(len(example_population))}\n",
    "\n",
    "for i in range(1000):\n",
    "    selected = roulette_selection(example_population)\n",
    "    index = example_population.index(selected)\n",
    "    counts[index] = counts[index] + 1\n",
    "    \n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.xticks(list(counts.keys()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Tournament selection, which we implemented earlier, suffers less from this problem. In tournament selection, we can adjust the _selective pressure_ by adjusting the tournament size. With our example population of size 3, a tournament size of 2 without replacement would imply a 67% chance of the best of the three individuals being selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tournament_size = 2\n",
    "\n",
    "counts = {x: 0 for x in range(len(example_population))}\n",
    "\n",
    "for i in range(1000):\n",
    "    selected = tournament_selection(example_population)\n",
    "    index = example_population.index(selected)\n",
    "    counts[index] = counts[index] + 1\n",
    "    \n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.xticks(list(counts.keys()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's also compare this to the population with a more equal spread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "example_population = [ [1,1,1,1,1], [0,1,1,1,1], [0,0,1,1,1], [0,0,0,1,1], [0,0,0,0,1], [0,0,0,0,0]  ]\n",
    "\n",
    "counts = {x: 0 for x in range(len(example_population))}\n",
    "\n",
    "for i in range(1000):\n",
    "    selected = tournament_selection(example_population)\n",
    "    index = example_population.index(selected)\n",
    "    counts[index] = counts[index] + 1\n",
    "    \n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.xticks(list(counts.keys()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To see the effects of the tournament size on the selection, let's repeat this with a larger tournament size, which means higher selective pressure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tournament_size = 4\n",
    "\n",
    "counts = {x: 0 for x in range(len(example_population))}\n",
    "\n",
    "for i in range(1000):\n",
    "    selected = tournament_selection(example_population, replacement=True)\n",
    "    index = example_population.index(selected)\n",
    "    counts[index] = counts[index] + 1\n",
    "    \n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.xticks(list(counts.keys()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Even with small tournament size the worst individual was not chosen in any of these cases. The reason is that we are using tournament selection _without_ replacement. If we pick any two individuals out of `example_population`, the individual with fitness 0 will _always_ be worse. If we use replacement, then there is a chance that the worst individual gets selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tournament_size = 2\n",
    "\n",
    "counts = {x: 0 for x in range(len(example_population))}\n",
    "\n",
    "for i in range(1000):\n",
    "    selected = tournament_selection(example_population, replacement=True)\n",
    "    index = example_population.index(selected)\n",
    "    counts[index] = counts[index] + 1\n",
    "    \n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.xticks(list(counts.keys()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can also observe the effects of the selective pressure throughout evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "from IPython.utils import io\n",
    "\n",
    "elite_size = 1\n",
    "selection = tournament_selection\n",
    "tournament_sizes = [1, 2, 5, 10]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 4))\n",
    "for tournament_size in tournament_sizes:\n",
    "    fitness_values, diversity_values, mean_fitness_values = [], [], []\n",
    "    with io.capture_output() as captured: \n",
    "        ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Tournament size {tournament_size}\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Tournament size {tournament_size}\")\n",
    "    axes[2].plot(fitness_values, label=f\"Tournament size {tournament_size}\")\n",
    "\n",
    "axes[0].set_title('Population Diversity')\n",
    "axes[0].legend()\n",
    "axes[1].set_title('Mean Population Fitness')\n",
    "axes[1].legend()\n",
    "axes[2].set_title('Best Fitness Evolution')\n",
    "axes[2].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Too little selective pressure (e.g., tournament size of 1) tends to be bad. Very large tournaments might be too eager (which is not so much of a problem in one max though)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Should we use fitness proportionate selection or tournament selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 4))\n",
    "n = 100\n",
    "with io.capture_output() as captured: \n",
    "    fitness_values = []\n",
    "    diversity_values = []\n",
    "    mean_fitness_values = []\n",
    "    selection = tournament_selection\n",
    "    tournament_size = 2\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Tournament size {tournament_size}\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Tournament size {tournament_size}\")\n",
    "    axes[2].plot(fitness_values, label=f\"Tournament size {tournament_size}\")\n",
    "\n",
    "    selection = roulette_selection\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Roulette wheel selection\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Roulette wheel selection\")\n",
    "    axes[2].plot(fitness_values, label=f\"Roulette wheel selection\")\n",
    "\n",
    "axes[0].set_title('Population Diversity')\n",
    "axes[0].legend()\n",
    "axes[1].set_title('Mean Population Fitness')\n",
    "axes[1].legend()\n",
    "axes[2].set_title('Best Fitness Evolution')\n",
    "axes[2].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "An alternative selection operator is _rank selection_, which is similar to fitness proportionate selection, except that the probability is calculated based on the _rank_ in the population sorted by fitness, rather than the actual fitness value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rank_bias = 2\n",
    "def rank_selection(population):\n",
    "    population.sort(key=lambda c: get_fitness(c), reverse=True)\n",
    "    \n",
    "    individuals = []\n",
    "    N = len(population)\n",
    "    for i in range(N):\n",
    "        f2 = rank_bias - (2 * i * (rank_bias - 1))/(N - 1)\n",
    "        individuals.append((population[i], f2))\n",
    "\n",
    "    # Now implement fitness proportionate selection using the f2 values\n",
    "    fitness_sum = sum([f for (c, f) in individuals])\n",
    "    pick = random.uniform(0, fitness_sum)\n",
    "    current = 0\n",
    "    for (chromosome, fitness) in individuals:\n",
    "        current += fitness\n",
    "        if current > pick:\n",
    "            return chromosome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The rank bias, which is in the range `[1,2]` allows us to adjust the selective pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "for rank_bias in [1, 1.5, 2]:\n",
    "    plt.plot([rank_bias - (2 * i * (rank_bias - 1)) / (N - 1) for i in range(100)], label = f\"Rank bias {rank_bias}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "With a bias of `2`, the worst individual has a 0% chance of being selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rank_bias = 2\n",
    "\n",
    "example_population = [ [1,1,1,1,1], [0,1,0,0,0], [1,0,0,0,0], [0,0,1,0,0], [0,0,0,1,0],[0,0,0,0,0] ]\n",
    "counts = {x: 0 for x in range(len(example_population))}\n",
    "\n",
    "for i in range(1000):\n",
    "    selected = rank_selection(example_population)\n",
    "    index = example_population.index(selected)\n",
    "    counts[index] = counts[index] + 1\n",
    "    \n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.xticks(list(counts.keys()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "With a bias of `1`, all individuals have the same probability of being selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rank_bias = 1\n",
    "\n",
    "example_population = [ [1,1,1,1,1], [0,1,0,0,0], [1,0,0,0,0], [0,0,1,0,0], [0,0,0,1,0],[0,0,0,0,0] ]\n",
    "counts = {x: 0 for x in range(len(example_population))}\n",
    "\n",
    "for i in range(1000):\n",
    "    selected = rank_selection(example_population)\n",
    "    index = example_population.index(selected)\n",
    "    counts[index] = counts[index] + 1\n",
    "    \n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.xticks(list(counts.keys()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We will select a reasonable default for the selective pressure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rank_bias = 1.4\n",
    "\n",
    "example_population = [ [1,1,1,1,1], [0,1,0,0,0], [1,0,0,0,0], [0,0,1,0,0], [0,0,0,1,0],[0,0,0,0,0] ]\n",
    "counts = {x: 0 for x in range(len(example_population))}\n",
    "\n",
    "for i in range(1000):\n",
    "    selected = rank_selection(example_population)\n",
    "    index = example_population.index(selected)\n",
    "    counts[index] = counts[index] + 1\n",
    "    \n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.xticks(list(counts.keys()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can again observe the effects of the rank bias on the evolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "selection = rank_selection\n",
    "rank_biases = [1, 1.3, 1.7, 2.0]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 4))\n",
    "for rank_bias in rank_biases:\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    with io.capture_output() as captured: \n",
    "        ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Rank bias {rank_bias}\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Rank bias {rank_bias}\")\n",
    "    axes[2].plot(fitness_values, label=f\"Rank bias {rank_bias}\")\n",
    "\n",
    "axes[0].set_title('Population Diversity')\n",
    "axes[0].legend()\n",
    "axes[1].set_title('Mean Population Fitness')\n",
    "axes[1].legend()\n",
    "axes[2].set_title('Best Fitness Evolution')\n",
    "axes[2].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Some variants of genetic algorithms use selection where each individual has the same chance of being selected. Although this removes selection pressure, this is usually compensated with a strong fitness-based survivor selection mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def uniform_selection(population):\n",
    "    return random.choice(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We would not usually use uniform selection without some other survival selection, but to see what the effects on the search are, let's put all the options together in one experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 4))\n",
    "n = 100\n",
    "with io.capture_output() as captured: \n",
    "    rank_bias = 1.4\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    selection = tournament_selection\n",
    "    tournament_size = 2\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Rank {rank_bias}\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Rank {rank_bias}\")\n",
    "    axes[2].plot(fitness_values, label=f\"Rank {rank_bias}\")\n",
    "\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    selection = tournament_selection\n",
    "    tournament_size = 2\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Tournament size {tournament_size}\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Tournament size {tournament_size}\")\n",
    "    axes[2].plot(fitness_values, label=f\"Tournament size {tournament_size}\")\n",
    "\n",
    "    selection = roulette_selection\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Roulette wheel selection\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Roulette wheel selection\")\n",
    "    axes[2].plot(fitness_values, label=f\"Roulette wheel selection\")\n",
    "\n",
    "    selection = uniform_selection\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Uniform selection\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Uniform selection\")\n",
    "    axes[2].plot(fitness_values, label=f\"Uniform selection\")\n",
    "\n",
    "axes[0].set_title('Population Diversity')\n",
    "axes[0].legend()\n",
    "axes[1].set_title('Mean Population Fitness')\n",
    "axes[1].legend()\n",
    "axes[2].set_title('Best Fitness Evolution')\n",
    "axes[2].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Survivor selection and parent selection are not independent: As an example, let's consider the effects of selective pressure on the generational GA and the steady state GA. We'll run tournament selection with two different tournament sizes to represent reasonablwe and high selective pressure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "With high selective pressure, the steady state GA maintains very high diversity, even though the best fitness improves reasonably over time. The reason is that with a large tournament size of 6 (with a population size of 20) the parent selection will repeatedly select the same few individuals with a high probability. If the result leads to an improvement, these are replaced but will be picked again with high probability afterwards, while large parts of the population (worse individuals that keep losing tournaments) will simply remain unchanged. This is also reflected by the lower average fitness in the population. For the generational GA the high selective pressure has the opposite effect: The population loses diversity very quickly, because most offspring will be produced from the same few parents. For one max, this doesn't appear to be a bad thing though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Alternative Crossover Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Our crossover operator so far only considers a single point for crossing two individuals. While this is the most common variant in practice, there is one potential downside: Only locally neighbouring genetic material is preserved; if a parent has relevant genes at the beginning and the end of the chromosome, these will not be inherited to the offspring directly. One way to circumvent this is by defining more than one crossover point. For example, we can define a two-point crossover operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def twopoint_crossover(parent1, parent2):\n",
    "    pos1 = random.randint(1, len(parent1))\n",
    "    pos2 = random.randint(pos1, len(parent1))\n",
    "    offspring1 = parent1[:pos1] + parent2[pos1:pos2] + parent1[pos2:]\n",
    "    offspring2 = parent2[:pos1] + parent1[pos1:pos2] + parent2[pos2:]\n",
    "    return offspring1, offspring2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "parent1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "parent2 = [1,1,1,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In the single point crossover, the offspring of `parent1` and `parent2` will _always_ be either a sequence of `0` followed by a sequence of `1`, or vice versa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "singlepoint_crossover(parent1, parent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In the two point crossover, there will be some variation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "twopoint_crossover(parent1, parent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It is not common to increase the number of crossover points beyond two, but instead of more variation is required, it is simply possible to _uniformly_ select genes from either of the parents, resulting in _uniform crossover_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def uniform_crossover(parent1, parent2):\n",
    "    offspring1 = []\n",
    "    offspring2 = []\n",
    "    for pos in range(len(parent1)):\n",
    "        if random.choice([True, False]):\n",
    "            offspring1.append(parent1[pos])\n",
    "            offspring2.append(parent2[pos])\n",
    "        else:\n",
    "            offspring1.append(parent2[pos])\n",
    "            offspring2.append(parent1[pos])\n",
    "    return offspring1, offspring2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Applying this to `parent1` and `parent2` from above, we will see offspring consisting of more variation in `1`s and `0`s, but these will always be chosen from parents and not random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "uniform_crossover(parent1, parent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The importance and influence of the crossover operator on the search is part of active research, and also depends on the problem we are trying to solve. To see whether there are any benefits to using crossover on our one max example, we can conduct a _headless chicken_ test: During crossover, we use a randomly generated individual as one of the parents. If the search still performs as well, then the crossover operator actually just serves as a kind of macro-mutation. If the search no longer performs as well, then it is the actual combination of parent genetic material that leads to an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def chicken_crossover(parent1, parent2):\n",
    "    offspring1 = []\n",
    "    offspring2 = []\n",
    "    parent2 = get_random_solution()\n",
    "    for pos in range(len(parent1)):\n",
    "        if random.choice([True, False]):\n",
    "            offspring1.append(parent1[pos])\n",
    "            offspring2.append(parent2[pos])\n",
    "        else:\n",
    "            offspring1.append(parent2[pos])\n",
    "            offspring2.append(parent1[pos])\n",
    "    return offspring1, offspring2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We will run the usual combination of experiments and analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 4))\n",
    "n = 100\n",
    "with io.capture_output() as captured: \n",
    "    crossover = singlepoint_crossover\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Singlepoint\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Singlepoint\")\n",
    "    axes[2].plot(fitness_values, label=f\"Singlepoint\")\n",
    "\n",
    "    crossover = uniform_crossover\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Uniform\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Uniform\")\n",
    "    axes[2].plot(fitness_values, label=f\"Uniform\")\n",
    "    \n",
    "    crossover = twopoint_crossover\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Twopoint\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Twopoint\")\n",
    "    axes[2].plot(fitness_values, label=f\"Twopoint\")\n",
    "    \n",
    "    crossover = chicken_crossover\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Chicken\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Chicken\")\n",
    "    axes[2].plot(fitness_values, label=f\"Chicken\")\n",
    "\n",
    "axes[0].set_title('Population Diversity')\n",
    "axes[0].legend()\n",
    "axes[1].set_title('Mean Population Fitness')\n",
    "axes[1].legend()\n",
    "axes[2].set_title('Best Fitness Evolution')\n",
    "axes[2].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This experiment just conducts a single run, and as usual we need to conduct an experiment with repetitions in order to draw conclusions. However, what most likely shows is that the headless chicken test leads to substantially worse results, while the uniform crossover tends to produce the best results. Consequently, it seems that crossover actually is useful for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mutation Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The mutation operator we considered so far flips each bit in a sequence of length $n$ with a probability of $1/n$. To be able to configure our genetic algorithm with alternative mutation operators, let's redefine this operator in a differently named function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def avg_mutate(individual):\n",
    "    P_mutate = 1/len(individual)\n",
    "    copy = individual[:]\n",
    "    for position in range(len(individual)):\n",
    "        if random.random() < P_mutate:\n",
    "            copy[position] = 1 - copy[position]\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "One of the reasons we used this operator so far was that it implicitly defines a mutation probability and we had one less parameter to worry about. However, when considering alternative operators, we will require a probability for applying mutation. This probability is usually fairly small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "P_mutate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A basic alternative operator would be to flip a single bit, with probability `P_mutate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def mutate1(individual):\n",
    "    copy = individual[:]\n",
    "    if random.random() < P_mutate:\n",
    "        position = random.randint(0, len(copy) - 1)\n",
    "        copy[position] = 1 - copy[position]\n",
    "    return copy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The scope for different operators on our bitvector representation is limited. Let's consider an alternative where we flip multiple bits at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def mutate10(individual):\n",
    "    copy = individual[:]\n",
    "    if random.random() < P_mutate:\n",
    "        for _ in range(10):\n",
    "            position = random.randint(0, len(copy) - 1)\n",
    "            copy[position] = 1 - copy[position]\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Given these three mutation operators, we can now run some comparative experiments again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "crossover = singlepoint_crossover\n",
    "selection = tournament_selection\n",
    "tournament_size = 2\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 4))\n",
    "n = 100\n",
    "max_steps = 5000\n",
    "with io.capture_output() as captured: \n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    mutate = avg_mutate\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Average Mutation\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Average Mutation\")\n",
    "    axes[2].plot(fitness_values, label=f\"Average Mutation\")\n",
    "\n",
    "    mutate = mutate1\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"1 Bit\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"1 Bit\")\n",
    "    axes[2].plot(fitness_values, label=f\"1 Bit\")\n",
    "    \n",
    "    mutate = mutate10\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"10 Bit\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"10 Bit\")\n",
    "    axes[2].plot(fitness_values, label=f\"10 Bit\")\n",
    "    \n",
    "\n",
    "axes[0].set_title('Population Diversity')\n",
    "axes[0].legend()\n",
    "axes[1].set_title('Mean Population Fitness')\n",
    "axes[1].legend()\n",
    "axes[2].set_title('Best Fitness Evolution')\n",
    "axes[2].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Mutating each bit with a probability of $1/n$ is beneficial for the diversity. Comparing the operators that flip 1 and 10 bits, we typically can observe that the 10 bit flip makes larger jumps in fitness improvements, but towards the end of the search it will struggle to home in on a solution as it flips _too much_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cellular Genetic Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The last aspect of the genetic algorithm we will consider is the population: The population is usually a multiset, and we mostly implemented it as a list to impose an order on individuals. A cellular evolutionary algorithm imposes a topology on the population. During reproduction, an individual is only allowed to mate with its neighbours, as defined by the topology (commonly rings, grids, or two-dimensional torus graphs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's put our population into a grid, i.e. a two-dimensional list. Let's assume we consider only the 4-neighbourhood (von Neumann neighbourhood) during selection, then we randomly select one of these 4 neighbours and the selected position itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def grid_selection(population, row, col):\n",
    "    neighbours = []\n",
    "    for dx in [-1, 1]:\n",
    "        if row + dx >= 0 and row + dx < len(population):\n",
    "            neighbours.append(population[row + dx][col])\n",
    "    for dy in [-1, 0, 1]:\n",
    "        if col + dy >= 0 and col + dy < len(population):\n",
    "            neighbours.append(population[row][col + dy])\n",
    "\n",
    "    return random.choice(neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The genetic algorithm needs to be modified such that the population is a properly initialised grid, and then uses the `grid_selection` we just defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "grid_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cellular_ga():\n",
    "    fitness_values.clear()\n",
    "    population = [[get_random_solution() for _ in range(grid_size)] for _ in range(grid_size)]\n",
    "\n",
    "    diversity_values.append(pairwise_distance([y for x in population for y in x]))\n",
    "    mean_fitness_values.append(mean([get_fitness(x) for x in [y for x in population for y in x]]))\n",
    "\n",
    "    best_fitness = -1\n",
    "    for p in [y for x in population for y in x]:\n",
    "        fitness = get_fitness(p)\n",
    "        if fitness > best_fitness:\n",
    "            best_fitness = fitness\n",
    "        fitness_values.append(best_fitness)\n",
    "        \n",
    "    while len(fitness_values) < max_steps:\n",
    "        new_population = []\n",
    "        for row in range(grid_size):\n",
    "            new_population.append([])\n",
    "            for col in range(grid_size):\n",
    "                parent1 = grid_selection(population, row, col)\n",
    "                parent2 = grid_selection(population, row, col)\n",
    "\n",
    "                if random.random() < P_xover:\n",
    "                    offspring1, offspring2 = crossover(parent1, parent2)\n",
    "                else:\n",
    "                    offspring1, offspring2 = parent1[:], parent2[:]\n",
    "\n",
    "                offspring = mutate(random.choice([offspring1, offspring2]))\n",
    "\n",
    "                if get_fitness(offspring) >= get_fitness(population[row][col]):\n",
    "                    new_population[row].append(offspring)\n",
    "                else:\n",
    "                    new_population[row].append(population[row][col])  \n",
    "                \n",
    "                if get_fitness(offspring) > best_fitness:\n",
    "                    best_fitness = get_fitness(offspring)\n",
    "                fitness_values.append(best_fitness)\n",
    "\n",
    "        population = new_population\n",
    "        \n",
    "        diversity_values.append(pairwise_distance([y for x in population for y in x]))\n",
    "        mean_fitness_values.append(mean([get_fitness(x) for x in [y for x in population for y in x]]))\n",
    "\n",
    "    return max([y for x in population for y in x], key=lambda k: get_fitness(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "When producing the next generation the cellular GA iterates over the grid, and produces an offspring at each grid location using only the neighbourhood for reproduction. We have implemented an elitist approach where the grid location is only replaced with the offspring if the offspring has the same or better fitness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mutate = avg_mutate\n",
    "crossover = singlepoint_crossover\n",
    "selection = tournament_selection\n",
    "tournament_size = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 4))\n",
    "n = 100\n",
    "max_steps = 5000\n",
    "with io.capture_output() as captured: \n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    ga()\n",
    "    axes[0].plot(diversity_values, label=f\"GA\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"GA\")\n",
    "    axes[2].plot(fitness_values, label=f\"GA\")\n",
    "\n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    steadystatega()\n",
    "    axes[0].plot(diversity_values, label=f\"SS-GA\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"SS-GA\")\n",
    "    axes[2].plot(fitness_values, label=f\"SS-GA\")\n",
    "    \n",
    "    fitness_values = []\n",
    "    mean_fitness_values = []\n",
    "    diversity_values = []\n",
    "    cellular_ga()\n",
    "    axes[0].plot(diversity_values, label=f\"Cellular GA\")\n",
    "    axes[1].plot(mean_fitness_values, label=f\"Cellular GA\")\n",
    "    axes[2].plot(fitness_values, label=f\"Cellular GA\")\n",
    "        \n",
    "\n",
    "axes[0].set_title('Population Diversity')\n",
    "axes[0].legend()\n",
    "axes[1].set_title('Mean Population Fitness')\n",
    "axes[1].legend()\n",
    "axes[2].set_title('Best Fitness Evolution')\n",
    "axes[2].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For larger grids the cellular GA may be slower initially -- it takes longer for genetic material to spread across the population of a large grid. This, however, is also its benefit: Premature convergence is less likely to occur."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
